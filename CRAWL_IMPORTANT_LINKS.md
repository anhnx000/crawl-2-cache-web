# HÆ°á»›ng dáº«n Cache Important Links

## ğŸ¯ Tá»•ng quan

File `important_links.json` chá»©a **16,304 important links** cáº§n cache.

## ğŸ“‹ CÃ¡c bÆ°á»›c thá»±c hiá»‡n

### BÆ°á»›c 1: Äáº£m báº£o Proxy Ä‘ang cháº¡y

Má»Ÿ terminal má»›i vÃ  cháº¡y proxy:

```bash
cd /home/xuananh/work_1/anhnx/crawl-2
export LIVE_FALLBACK=true
python3 app.py
```

Proxy sáº½ cháº¡y táº¡i `http://localhost:5002`

---

### BÆ°á»›c 2A: Test vá»›i 30 URLs Ä‘áº§u tiÃªn (Khuyáº¿n nghá»‹)

**Cháº¡y lá»‡nh nÃ y Ä‘á»ƒ test trÆ°á»›c:**

```bash
cd /home/xuananh/work_1/anhnx/crawl-2

python3 auto_crawl_proxy.py \
  --json-file important_links.json \
  --json-start-index 0 \
  --json-end-index 30 \
  --follow-depth 3 \
  --concurrency 5 \
  --delay 0.3 \
  --max-retries 10 \
  --auto-pagination \
  --verbose
```

**Giáº£i thÃ­ch tham sá»‘:**
- `--json-file important_links.json` - File chá»©a danh sÃ¡ch URLs
- `--json-start-index 0` - Báº¯t Ä‘áº§u tá»« URL thá»© 0
- `--json-end-index 30` - Káº¿t thÃºc táº¡i URL thá»© 30 (crawl 30 URLs Ä‘áº§u)
- `--follow-depth 3` - Tá»± Ä‘á»™ng crawl links tÃ¬m Ä‘Æ°á»£c vá»›i Ä‘á»™ sÃ¢u 3 táº§ng
- `--concurrency 5` - Crawl 5 URLs Ä‘á»“ng thá»i
- `--delay 0.3` - GiÃ£n cÃ¡ch 0.3s giá»¯a cÃ¡c request
- `--max-retries 10` - Retry tá»‘i Ä‘a 10 láº§n náº¿u gáº·p lá»—i
- `--auto-pagination` - Tá»± Ä‘á»™ng phÃ¡t hiá»‡n vÃ  crawl táº¥t cáº£ cÃ¡c trang
- `--verbose` - Hiá»ƒn thá»‹ chi tiáº¿t

**Káº¿t quáº£ mong Ä‘á»£i:**
- Sáº½ cache 30 important links ban Ä‘áº§u
- Tá»± Ä‘á»™ng extract vÃ  cache thÃªm cÃ¡c links liÃªn quan (depth 1, 2, 3)
- Tá»•ng sá»‘ URLs Ä‘Æ°á»£c cache cÃ³ thá»ƒ lÃ  100-500+ URLs

---

### BÆ°á»›c 2B: Cache FULL toÃ n bá»™ 16,304 important links

**Sau khi test thÃ nh cÃ´ng, cháº¡y lá»‡nh nÃ y Ä‘á»ƒ cache toÃ n bá»™:**

```bash
cd /home/xuananh/work_1/anhnx/crawl-2

nohup python3 auto_crawl_proxy.py \
  --json-file important_links.json \
  --follow-depth 3 \
  --concurrency 5 \
  --delay 0.3 \
  --max-retries 10 \
  --auto-pagination \
  > cache_important_full.log 2>&1 &
```

**LÆ°u Ã½:**
- KhÃ´ng cÃ³ `--json-end-index` â†’ crawl táº¥t cáº£
- Cháº¡y á»Ÿ background vá»›i `nohup` vÃ  `&`
- Log Ä‘Æ°á»£c ghi vÃ o `cache_important_full.log`

---

### BÆ°á»›c 3: Theo dÃµi tiáº¿n trÃ¬nh

**Kiá»ƒm tra nhanh:**
```bash
./check_progress.sh
```

**Xem log realtime:**
```bash
tail -f cache_important_full.log
```

**Kiá»ƒm tra process:**
```bash
ps aux | grep auto_crawl_proxy.py
```

**Äáº¿m URLs Ä‘Ã£ cache:**
```bash
grep -c "âœ… \[200\]" cache_important_full.log
```

---

## â±ï¸ Æ¯á»›c tÃ­nh thá»i gian

- **30 URLs Ä‘áº§u:** ~2-5 phÃºt
- **ToÃ n bá»™ 16,304 URLs:** ~8-15 giá» (tÃ¹y Ä‘á»™ sÃ¢u vÃ  sá»‘ links tÃ¬m Ä‘Æ°á»£c)

Vá»›i depth=3 vÃ  auto-pagination, tá»•ng sá»‘ URLs thá»±c táº¿ sáº½ cao hÆ¡n ráº¥t nhiá»u (cÃ³ thá»ƒ 50,000-100,000+ URLs).

---

## ğŸ› ï¸ CÃ¡c lá»‡nh há»¯u Ã­ch

### Dá»«ng crawling
```bash
pkill -f auto_crawl_proxy.py
```

### Resume tá»« index cá»¥ thá»ƒ (náº¿u bá»‹ giÃ¡n Ä‘oáº¡n)
```bash
# VÃ­ dá»¥: tiáº¿p tá»¥c tá»« URL thá»© 1000
python3 auto_crawl_proxy.py \
  --json-file important_links.json \
  --json-start-index 1000 \
  --follow-depth 3 \
  --concurrency 5 \
  --delay 0.3
```

### Verify Ä‘Ã£ cache bao nhiÃªu important links
```bash
python3 verify_cached_links.py
```

---

## ğŸ“Š Hiá»ƒu vá» Follow Depth

**Depth = 0:** Chá»‰ cache cÃ¡c URLs trong important_links.json

**Depth = 1:** Cache important links + táº¥t cáº£ links tÃ¬m Ä‘Æ°á»£c tá»« trang Ä‘Ã³

**Depth = 2:** Cache depth 1 + táº¥t cáº£ links tá»« cÃ¡c trang depth 1

**Depth = 3:** Cache depth 2 + táº¥t cáº£ links tá»« cÃ¡c trang depth 2

**Khuyáº¿n nghá»‹:** Depth 3 Ä‘á»ƒ cache Ä‘áº§y Ä‘á»§ toÃ n bá»™ trang web

---

## ğŸ¯ Káº¿t quáº£ cuá»‘i cÃ¹ng

Sau khi hoÃ n thÃ nh, báº¡n sáº½ cÃ³:
- âœ… Táº¥t cáº£ 16,304 important links Ä‘Æ°á»£c cache
- âœ… Táº¥t cáº£ links liÃªn quan (documents, pagination, sub-pages) Ä‘Æ°á»£c cache
- âœ… ToÃ n bá»™ trang web cÃ³ thá»ƒ browse offline qua proxy

