# ğŸš€ Quick Start - Cache Important Links

## BÆ°á»›c 1: Cháº¡y Proxy (Terminal 1)

```bash
cd /home/xuananh/work_1/anhnx/crawl-2
export LIVE_FALLBACK=true
python3 app.py
```

Giá»¯ terminal nÃ y cháº¡y!

---

## BÆ°á»›c 2: Chá»n cÃ¡ch cache (Terminal 2)

### Option A: Test 30 URLs Ä‘áº§u tiÃªn (âš¡ Nhanh - 2 phÃºt)

```bash
cd /home/xuananh/work_1/anhnx/crawl-2
./crawl_30_first.sh
```

### Option B: Cache FULL 16,304 URLs (ğŸŒ LÃ¢u - 8-15 giá»)

```bash
cd /home/xuananh/work_1/anhnx/crawl-2
./crawl_full.sh
```

### Option C: Cache má»™t khoáº£ng cá»¥ thá»ƒ

```bash
cd /home/xuananh/work_1/anhnx/crawl-2
./crawl_range.sh 0 100        # Cache URLs 0-100
./crawl_range.sh 1000 2000    # Cache URLs 1000-2000
```

---

## BÆ°á»›c 3: Theo dÃµi tiáº¿n trÃ¬nh

### Kiá»ƒm tra nhanh
```bash
./check_progress.sh
```

### Xem log realtime
```bash
tail -f cache_important_full.log
```

### Verify Ä‘Ã£ cache bao nhiÃªu important links
```bash
python3 verify_cached_links.py
```

---

## âš¡ Quick Commands

**Dá»«ng crawl:**
```bash
pkill -f auto_crawl_proxy.py
```

**Kiá»ƒm tra process:**
```bash
ps aux | grep auto_crawl_proxy.py
```

**Äáº¿m sá»‘ URLs Ä‘Ã£ cache:**
```bash
find cache -name "*.bin" | wc -l
```

---

## ğŸ“Š ThÃ´ng tin

- **File nguá»“n:** `important_links.json`
- **Tá»•ng URLs:** 16,304
- **Follow depth:** 3 (tá»± Ä‘á»™ng crawl links liÃªn quan)
- **Auto pagination:** CÃ³ (tá»± Ä‘á»™ng crawl táº¥t cáº£ cÃ¡c trang)
- **Concurrency:** 5 requests Ä‘á»“ng thá»i
- **Delay:** 0.3s giá»¯a cÃ¡c requests
- **Max retries:** 10 láº§n

---

## ğŸ¯ Káº¿t quáº£

Sau khi hoÃ n thÃ nh:
- âœ… Táº¥t cáº£ 16,304 important links Ä‘Æ°á»£c cache
- âœ… Táº¥t cáº£ links liÃªn quan (vá»›i depth 3) Ä‘Æ°á»£c cache
- âœ… Website cÃ³ thá»ƒ browse offline hoÃ n toÃ n

**Tá»•ng sá»‘ URLs thá»±c táº¿ sáº½ cao hÆ¡n nhiá»u (50,000-100,000+ URLs)**

