# ğŸ¯ START HERE - HÆ°á»›ng dáº«n nhanh nháº¥t

## ğŸš€ CÃ¡ch 1: ALL-IN-ONE (ÄÆ¡n giáº£n nháº¥t! â­)

```bash
cd /home/xuananh/work_1/anhnx/crawl-2
./start_all.sh
```

Script nÃ y sáº½ **Tá»° Äá»˜NG**:
- âœ… Dá»«ng processes cÅ© (náº¿u cÃ³)
- âœ… Cháº¡y proxy (online mode)
- âœ… Cháº¡y crawler
- âœ… Hiá»ƒn thá»‹ log realtime
- âœ… Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng theo dÃµi (processes váº«n cháº¡y)

**â†’ Chá»‰ 1 lá»‡nh duy nháº¥t, khÃ´ng cáº§n má»Ÿ nhiá»u terminal!**

---

## âš¡ CÃ¡ch 2: Script hÆ°á»›ng dáº«n tá»«ng bÆ°á»›c

```bash
cd /home/xuananh/work_1/anhnx/crawl-2
./START_CRAWL_FULL.sh
```

Script nÃ y sáº½:
- âœ… Kiá»ƒm tra proxy cÃ³ cháº¡y chÆ°a
- âœ… HÆ°á»›ng dáº«n cháº¡y proxy náº¿u chÆ°a cÃ³
- âœ… Báº¯t Ä‘áº§u crawl tá»± Ä‘á»™ng
- âœ… Hiá»ƒn thá»‹ log preview

---

## ğŸ› ï¸ CÃ¡ch 3: Thá»§ cÃ´ng tá»«ng bÆ°á»›c

### Terminal 1: Cháº¡y Proxy
```bash
cd /home/xuananh/work_1/anhnx/crawl-2
./start_online.sh
```
**Giá»¯ terminal nÃ y cháº¡y!**

### Terminal 2: Cháº¡y Crawler
```bash
cd /home/xuananh/work_1/anhnx/crawl-2
./crawl_full.sh
```

### Terminal 3: Monitor
```bash
cd /home/xuananh/work_1/anhnx/crawl-2
tail -f cache_important_full.log
```

---

## ğŸ“Š Theo dÃµi tiáº¿n trÃ¬nh

```bash
# Quick check
./check_progress.sh

# Realtime log
tail -f cache_important_full.log

# Watch continuous
watch -n 10 './check_progress.sh'
```

---

## ğŸ›‘ Dá»«ng crawl

```bash
pkill -f auto_crawl_proxy.py
```

---

## ğŸ”Œ Xem káº¿t quáº£ Offline

Sau khi crawl xong (hoáº·c Ä‘ang crawl), báº¡n cÃ³ thá»ƒ browse offline:

### Terminal 1: Cháº¡y proxy offline
```bash
./start_offline.sh
```

### Browser: Má»Ÿ
```
http://localhost:5002
```

---

## â±ï¸ Thá»i gian Æ°á»›c tÃ­nh

- **30 URLs Ä‘áº§u** (test): 2-5 phÃºt
- **Full 16,304 URLs**: 8-15 giá»
- **Tá»•ng URLs thá»±c táº¿**: 50,000-100,000+ (do depth=3 + pagination)

---

## ğŸ“š TÃ i liá»‡u Ä‘áº§y Ä‘á»§

```bash
cat QUICK_START.md        # Quick start
cat OFFLINE_MODE.md       # Offline mode
cat QUICK_REFERENCE.md    # Command reference
cat PROJECT_STRUCTURE.md  # Project structure
```

---

## ğŸ’¡ LÆ°u Ã½ quan trá»ng

1. **LuÃ´n cháº¡y proxy TRÆ¯á»šC khi crawl**
   - `./start_online.sh` cho crawling
   - `./start_offline.sh` cho browse offline

2. **Proxy vÃ  Crawler lÃ  2 process riÃªng**
   - Proxy: `app.py` (port 5002)
   - Crawler: `auto_crawl_proxy.py` (crawl qua proxy)

3. **Cache Ä‘Æ°á»£c chia sáº»**
   - Táº¥t cáº£ tools dÃ¹ng chung thÆ° má»¥c `cache/`
   - CÃ³ thá»ƒ dá»«ng vÃ  resume báº¥t cá»© lÃºc nÃ o

---

## ğŸ¯ Workflow Ä‘áº§y Ä‘á»§

```bash
# 1. Cháº¡y proxy (Terminal 1)
./start_online.sh

# 2. Báº¯t Ä‘áº§u crawl (Terminal 2)
./START_CRAWL_FULL.sh

# 3. Monitor (Terminal 3)
tail -f cache_important_full.log

# 4. Sau khi xong, browse offline
# Ctrl+C á»Ÿ Terminal 1, sau Ä‘Ã³:
./start_offline.sh

# 5. Má»Ÿ browser
# http://localhost:5002
```

---

## ğŸ†˜ Troubleshooting

### Lá»—i "Connection refused"
â†’ Proxy chÆ°a cháº¡y, cháº¡y `./start_online.sh`

### Crawler dá»«ng Ä‘á»™t ngá»™t
â†’ Kiá»ƒm tra log: `cat cache_important_full.log`

### URLs khÃ´ng load (404)
â†’ ChÆ°a cache, cháº¡y láº¡i vá»›i online mode

### Kiá»ƒm tra process Ä‘ang cháº¡y
```bash
ps aux | grep -E "(app.py|auto_crawl)"
```

---

**Báº¯t Ä‘áº§u ngay: `./START_CRAWL_FULL.sh`** ğŸš€

